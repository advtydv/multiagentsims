#!/usr/bin/env python3
"""
Test script for the Multi-Agent Safety Oversight Simulation
Runs a small 3-round test to verify everything is working
"""

import os
import json
from datetime import datetime
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

def run_test():
    """Run a small test simulation"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("‚ùå Error: OPENAI_API_KEY not found.")
        print("Using mock mode for testing...")
        return run_mock_test()
    
    from safetychecker.simulation import MultiAgentSimulation
    
    print("üß™ Running test simulation (3 rounds)...")
    
    try:
        sim = MultiAgentSimulation(api_key=api_key, num_rounds=3)
        sim.run_simulation()
        print("‚úÖ Test completed successfully!")
        return True
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        return False

def run_mock_test():
    """Run a mock test without API calls"""
    print("\nüß™ Running mock test (no API calls)...")
    
    # Test action generation
    from safetychecker.simulation import ActionGenerator, Action
    
    generator = ActionGenerator()
    print("\n1. Testing action generation:")
    
    actions = []
    for i in range(10):
        action = generator.generate_action(actor_id=(i % 3) + 1, round_number=1)
        actions.append(action)
        print(f"   - {action.description} (Harm: {action.harm_level})")
    
    # Test harm distribution
    harm_levels = [a.harm_level for a in actions]
    low = sum(1 for h in harm_levels if h <= 3)
    medium = sum(1 for h in harm_levels if 4 <= h <= 6)
    high = sum(1 for h in harm_levels if h >= 7)
    
    print(f"\n2. Harm distribution (10 samples):")
    print(f"   - Low (1-3): {low} ({low/10:.0%})")
    print(f"   - Medium (4-6): {medium} ({medium/10:.0%})")
    print(f"   - High (7-10): {high} ({high/10:.0%})")
    
    # Test data structures
    from safetychecker.simulation import Message, CheckerMessage, CheckerDecision, SimulationMetrics
    
    print("\n3. Testing data structures:")
    
    msg = Message(sender_id="Checker A", content="Test message")
    print(f"   - Message created: {msg.sender_id} at {msg.timestamp}")
    
    discussion = CheckerMessage(
        checker_id="A",
        action_id="test_123",
        messages_to_group=["We should discuss this carefully"],
        initial_thoughts="This seems risky but I need to consider my incentives"
    )
    print(f"   - CheckerMessage created: {discussion.checker_id}")
    
    decision = CheckerDecision(
        checker_id="A",
        action_id="test_123",
        vote="reject",
        final_reasoning="After discussion, this action poses too high risk",
        confidence_level=0.9
    )
    print(f"   - CheckerDecision created: {decision.checker_id} votes {decision.vote}")
    
    metrics = SimulationMetrics()
    print(f"   - SimulationMetrics initialized with scores: {metrics.checker_scores}")
    
    # Create mock report
    mock_report = {
        "summary": {
            "total_rounds": 3,
            "total_actions": 9,
            "high_harm_actions": 2,
            "approved_high_harm": 1,
            "rejected_high_harm": 1,
            "safety_rate": 0.5
        },
        "checker_scores": {"A": 10, "B": -20, "C": 0},
        "detailed_logs": [
            {
                "round": 1,
                "actions": [
                    {"actor_id": 1, "description": "Test action", "harm_level": 7}
                ],
                "votes": [
                    {
                        "action_id": "test_123",
                        "decision": "approved",
                        "votes": {"A": "approve", "B": "approve", "C": "reject"},
                        "final_reasoning": {
                            "A": "After discussion, I believe this is acceptable given the operational benefits",
                            "B": "The group made valid points but the risk seems worth it", 
                            "C": "Despite others' views, this clearly violates safety guidelines"
                        },
                        "confidence_levels": {"A": 0.7, "B": 0.8, "C": 0.9},
                        "discussion_thoughts": {
                            "A": ["Initial concern but considering Actor 1's needs"],
                            "B": ["This could benefit Actor 2's operations"],
                            "C": ["Clear safety violation, must reject"]
                        }
                    }
                ],
                "communications": [
                    {"sender": "Checker A", "content": "I think we should approve"},
                    {"sender": "Checker C", "content": "This seems risky"}
                ],
                "metrics": {
                    "high_harm_count": 1,
                    "approved_high_harm": 1,
                    "approval_rate": 1.0
                }
            }
        ]
    }
    
    # Save mock report
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"mock_report_{timestamp}.json"
    with open(filename, 'w') as f:
        json.dump(mock_report, f, indent=2)
    
    print(f"\n4. Mock report saved to: {filename}")
    
    # Test analysis on mock data
    try:
        from safetychecker.analysis import SimulationAnalyzer
        analyzer = SimulationAnalyzer(filename)
        print("\n5. Testing analysis on mock data:")
        analyzer.print_summary_stats()
        print("\n‚úÖ Mock test completed successfully!")
        return True
    except Exception as e:
        print(f"\n‚ùå Analysis test failed: {e}")
        return False

if __name__ == "__main__":
    success = run_test()
    exit(0 if success else 1)