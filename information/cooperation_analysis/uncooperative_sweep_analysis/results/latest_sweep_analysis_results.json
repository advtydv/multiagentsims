{
  "sweep_info": {
    "sweep_dir": "complete_sweep_20250813_120459",
    "analysis_timestamp": "2025-08-13T14:40:12.500985",
    "total_simulations": 11
  },
  "raw_data": {
    "uncooperative_counts": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10
    ],
    "task_completions": [
      30,
      33,
      30,
      7,
      10,
      18,
      18,
      16,
      7,
      14,
      13
    ],
    "messages": [
      243,
      226,
      266,
      259,
      282,
      303,
      296,
      294,
      295,
      327,
      316
    ],
    "deceptions": [
      0,
      15,
      19,
      11,
      21,
      40,
      44,
      41,
      34,
      54,
      54
    ]
  },
  "statistical_analysis": {
    "normality_p_value": 0.13317443430423737,
    "is_normal": true,
    "pearson": {
      "r": -0.661863398213511,
      "p": 0.026529202331281945
    },
    "spearman": {
      "r": -0.5675190940205642,
      "p": 0.06860633629024922
    },
    "linear": {
      "coefficients": [
        -1.8545454545454538,
        27.09090909090909
      ],
      "r2": 0.4380631578947368,
      "rmse": 6.642214108598338
    },
    "quadratic": {
      "coefficients": [
        0.37296037296037404,
        -5.584149184149191,
        32.685314685314694
      ],
      "r2": 0.5762547908232118,
      "rmse": 5.767950412422168
    },
    "cubic": {
      "coefficients": [
        -0.04059829059829017,
        0.9819347319347236,
        -7.906371406371369,
        34.146853146853076
      ],
      "r2": 0.5880445344129557,
      "rmse": 5.687144356750584
    }
  },
  "key_findings": {
    "baseline_performance": 30,
    "best_performance": {
      "count": 1,
      "tasks": 33
    },
    "worst_performance": {
      "count": 3,
      "tasks": 7
    },
    "paradoxical_improvements": [
      [
        1,
        33,
        10.0
      ]
    ]
  }
}